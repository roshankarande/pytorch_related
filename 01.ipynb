{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression model class\n",
    "class LinearRegressionModel(nn.Module): # <- almost everything in PyTorch is a nn.Module (think of this as neural network lego blocks)\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.weights = nn.Parameter(torch.randn(1, # <- start with random weights (this will get adjusted as the model learns)\n",
    "                                                dtype=torch.float), # <- PyTorch loves float32 by default\n",
    "                                   requires_grad=True) # <- can we update this value with gradient descent?)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.randn(1, # <- start with random bias (this will get adjusted as the model learns)\n",
    "                                            dtype=torch.float), # <- PyTorch loves float32 by default\n",
    "                                requires_grad=True) # <- can we update this value with gradient descent?))\n",
    "\n",
    "    # Forward defines the computation in the model\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data (e.g. training/testing features)\n",
    "        return self.weights * x + self.bias # <- this is the linear regression formula (y = m*x + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(model.parameters())\n",
    "# model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X  = torch.arange(0,1,0.02).reshape(-1,1)\n",
    "w, b = 0.7, 0.3\n",
    "\n",
    "y = X*w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:40], y[:40]\n",
    "X_test, y_test = X[40:], y[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optim = torch.optim.SGD(params=model.parameters(),lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a7888ca72940af9884400d25f48ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.1659\n",
      "Test Loss : 0.0023\n",
      "Test Loss : 0.0004\n",
      "Test Loss : 0.0001\n",
      "Test Loss : 0.0000\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "EPOCHS = 500\n",
    "\n",
    "for i in tqdm(range(EPOCHS)):\n",
    "\n",
    "    # Training \n",
    "    model.train()\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model(X_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if i%100 == 0:\n",
    "        print(f\"Test Loss : {test_loss :.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.6975], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3010], requires_grad=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModelv2(nn.Module):\n",
    "    \"\"\"Some Information about LinearRegressionModelv2\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=1,out_features=1)\n",
    "\n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        return self.linear_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModelv2()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optim = torch.optim.SGD(params=model.parameters(),lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e91c8a3dab40afbeb6fa462c094b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  0.1912\n",
      "Loss :  0.0006\n",
      "Loss :  0.0001\n",
      "Loss :  0.0000\n",
      "Loss :  0.0000\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "EPOCHS = 500\n",
    "\n",
    "for i in tqdm(range(EPOCHS)):\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    \n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "\n",
    "# I think this way it is more efficient\n",
    "    if i % 100 == 0:\n",
    "        with torch.inference_mode():\n",
    "            test_pred = model(X_test)\n",
    "            test_loss = loss_fn(test_pred, y_test)\n",
    "            print(f\"Loss : {test_loss : .4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_layer.weight', tensor([[0.6987]])),\n",
       "             ('linear_layer.bias', tensor([0.3005]))])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()\n",
    "# optim.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models/01_pytorch_workflow_model_1.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory \n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path \n",
    "MODEL_NAME = \"01_pytorch_workflow_model_1.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict \n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=model.state_dict(), # only saving the state_dict() only saves the models learned parameters\n",
    "           f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a fresh instance of LinearRegressionModelV2\n",
    "loaded_model = LinearRegressionModelv2()\n",
    "\n",
    "# Load model state dict \n",
    "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate loaded model\n",
    "loaded_model.eval()\n",
    "with torch.inference_mode():\n",
    "    test_pred = model(X_test)\n",
    "    loaded_model_pred = loaded_model(X_test)\n",
    "    \n",
    "torch.norm(test_pred - loaded_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "model = LinearRegressionModelv2()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optim = torch.optim.SGD(params=model.parameters(),lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters()).device, X_train.device\n",
    "# list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248e8bd9da9b4b41a3dda955533bb619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss :  0.1912| 0.3084445595741272\n",
      "Loss :  0.0006| 0.00014370800636243075\n",
      "Loss :  0.0001| 2.265658440592233e-05\n",
      "Loss :  0.0000| 3.572052946765325e-06\n",
      "Loss :  0.0000| 5.631786166304664e-07\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "EPOCHS = 500\n",
    "\n",
    "for i in tqdm(range(EPOCHS)):\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    \n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "\n",
    "# I think this way it is more efficient\n",
    "    if i % 100 == 0:\n",
    "        with torch.inference_mode():\n",
    "            test_pred = model(X_test)\n",
    "            test_loss = loss_fn(test_pred, y_test)\n",
    "            print(f\"Loss : {test_loss : .4f}| {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.6987]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3005], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {0: {'momentum_buffer': None}, 1: {'momentum_buffer': None}},\n",
       " 'param_groups': [{'lr': 0.1,\n",
       "   'momentum': 0,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'maximize': False,\n",
       "   'foreach': None,\n",
       "   'differentiable': False,\n",
       "   'params': [0, 1]}]}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
